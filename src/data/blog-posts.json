[
  {
    "id": "building-fastapi-microservices",
    "title": "BUILDING EVENT-DRIVEN MICROSERVICES WITH FASTAPI",
    "date": "2024-11-01",
    "excerpt": "A deep dive into architecting event-driven microservices using FastAPI, Domain-Driven Design, and clean architecture principles.",
    "tags": ["fastapi", "python", "microservices", "architecture"],
    "readTime": "10 min",
    "featured": true,
    "relatedProjectIds": ["event-driven-microservices", "qr-code-platform"],
    "contentBlocks": [
      {
        "type": "text",
        "content": "Event-driven microservices enable building scalable, maintainable systems that can handle complex business logic while remaining loosely coupled. In this post, I'll share lessons learned from building a production microservices platform serving 5,000+ users."
      },
      {
        "type": "heading",
        "content": "Why FastAPI for Microservices?",
        "metadata": { "level": 2 }
      },
      {
        "type": "text",
        "content": "FastAPI is an excellent choice for microservices due to its async capabilities, automatic OpenAPI documentation, and Pydantic validation. Combined with SQLAlchemy 2.0's async support, you can build high-performance services that handle hundreds of concurrent requests."
      },
      {
        "type": "code",
        "content": "from fastapi import FastAPI\nfrom pydantic import BaseModel\n\napp = FastAPI()\n\nclass Event(BaseModel):\n    type: str\n    data: dict\n\n@app.post('/events')\nasync def handle_event(event: Event):\n    # Process event asynchronously\n    return {'status': 'processed'}",
        "metadata": { "language": "python" }
      },
      {
        "type": "heading",
        "content": "Domain-Driven Design Principles",
        "metadata": { "level": 2 }
      },
      {
        "type": "text",
        "content": "Domain-Driven Design helps organize complex business logic into bounded contexts. Each microservice owns its domain model and communicates with others through well-defined interfaces. This isolation makes testing easier and allows teams to work independently."
      },
      {
        "type": "diagram",
        "content": "graph TB\n    subgraph Scan Context\n        A[Scan Service]\n        B[Analytics Engine]\n    end\n    subgraph Student Context\n        C[Student Service]\n        D[Data Integration]\n    end\n    subgraph Shared\n        E[Event Bus]\n        F[PostgreSQL]\n    end\n    A --> E\n    C --> E\n    E --> B\n    E --> D\n    A --> F\n    C --> F",
        "metadata": { "diagramType": "mermaid" }
      },
      {
        "type": "callout",
        "content": "Use bounded contexts to isolate domains and enable independent team work. Each context should have clear boundaries and well-defined interfaces.",
        "metadata": { "calloutType": "tip" }
      },
      {
        "type": "heading",
        "content": "Key Architecture Patterns",
        "metadata": { "level": 2 }
      },
      {
        "type": "text",
        "content": "Several patterns are essential for building maintainable microservices: Repository pattern for data access, Adapter pattern for external integrations, dependency injection for testability, and CQRS for separating reads from writes. Use domain events to communicate between services rather than tight coupling."
      },
      {
        "type": "heading",
        "content": "Repository Pattern Implementation",
        "metadata": { "level": 3 }
      },
      {
        "type": "code",
        "content": "from abc import ABC, abstractmethod\nfrom sqlalchemy.ext.asyncio import AsyncSession\n\nclass EventRepository(ABC):\n    @abstractmethod\n    async def save(self, event: Event) -> None:\n        pass\n\nclass SQLEventRepository(EventRepository):\n    def __init__(self, session: AsyncSession):\n        self.session = session\n    \n    async def save(self, event: Event) -> None:\n        self.session.add(event)\n        await self.session.commit()",
        "metadata": { "language": "python" }
      },
      {
        "type": "heading",
        "content": "Observability is Critical",
        "metadata": { "level": 2 }
      },
      {
        "type": "text",
        "content": "Instrument your services with Prometheus metrics, structured logging with Structlog, and distributed tracing with OpenTelemetry. This visibility is essential for debugging production issues."
      },
      {
        "type": "callout",
        "content": "Without proper observability, you're flying blind. Always implement metrics, logging, and tracing from day one.",
        "metadata": { "calloutType": "warning" }
      },
      {
        "type": "heading",
        "content": "Real-World Results",
        "metadata": { "level": 2 }
      },
      {
        "type": "text",
        "content": "Our QR code platform processes 500+ daily interactions with sub-second response times using these patterns. Proper architecture enables scaling both the system and the team. The event-driven approach allowed us to maintain 99.9% uptime while continuously deploying new features."
      },
      {
        "type": "callout",
        "content": "Start with a solid architecture from the beginning. Refactoring a monolith into microservices is exponentially harder than building it right from day one.",
        "metadata": { "calloutType": "important" }
      }
    ]
  },
  {
    "id": "oauth2-authentication-gateway",
    "title": "IMPLEMENTING ZERO-TRUST AUTHENTICATION WITH OAUTH2-PROXY",
    "date": "2024-10-15",
    "excerpt": "Building a distributed authentication gateway using OAuth2-Proxy, Traefik, and Keycloak SSO to protect 5,000+ users.",
    "tags": ["oauth2", "security", "authentication", "devops"],
    "readTime": "12 min",
    "featured": true,
    "relatedProjectIds": ["authentication-gateway"],
    "contentBlocks": [
      {
        "type": "text",
        "content": "Modern web applications require robust authentication and authorization. A zero-trust architecture ensures every request is authenticated and authorized before accessing protected resources. Here's how we built an authentication gateway serving 5,181+ active users."
      },
      {
        "type": "heading",
        "content": "The Zero-Trust Architecture",
        "metadata": { "level": 2 }
      },
      {
        "type": "text",
        "content": "OAuth2-Proxy acts as a reverse proxy that handles authentication before requests reach your application. Combined with Traefik as the ingress controller, you can protect entire services with just configuration changes. This pattern keeps authentication logic out of individual applications."
      },
      {
        "type": "diagram",
        "content": "graph LR\n    A[User] --> B[Traefik Ingress]\n    B --> C[OAuth2-Proxy]\n    C --> D{Authenticated?}\n    D -->|No| E[Keycloak SSO]\n    E --> A\n    D -->|Yes| F[Protected Service]\n    F --> G[PostgreSQL]\n    C --> H[Redis Session Store]",
        "metadata": { "diagramType": "mermaid" }
      },
      {
        "type": "heading",
        "content": "Keycloak for Centralized Identity",
        "metadata": { "level": 2 }
      },
      {
        "type": "text",
        "content": "Keycloak provides centralized identity management with SSO capabilities. Users log in once and access multiple applications seamlessly. It supports various authentication methods, role-based access control, and integrates with existing identity providers."
      },
      {
        "type": "code",
        "content": "# OAuth2-Proxy configuration\nupstreams:\n  - id: protected-service\n    uri: http://backend:8000\n    path: /\n\nproviders:\n  - id: keycloak\n    provider: oidc\n    clientID: my-app\n    clientSecret: ${CLIENT_SECRET}\n    oidcConfig:\n      issuerURL: https://keycloak.example.com/realms/myrealm\n      audienceClaims:\n        - aud\n      emailClaim: email\n      groupsClaim: groups",
        "metadata": { "language": "yaml" }
      },
      {
        "type": "heading",
        "content": "Implementation Details",
        "metadata": { "level": 2 }
      },
      {
        "type": "text",
        "content": "The implementation consists of several key components working together:"
      },
      {
        "type": "heading",
        "content": "OAuth2-Proxy Deployment",
        "metadata": { "level": 3 }
      },
      {
        "type": "text",
        "content": "Deploy OAuth2-Proxy as a sidecar container alongside your application. Configure it to validate tokens with Keycloak and maintain session state in Redis for horizontal scalability."
      },
      {
        "type": "heading",
        "content": "Traefik Middleware Configuration",
        "metadata": { "level": 3 }
      },
      {
        "type": "code",
        "content": "# Traefik middleware for authentication\napiVersion: traefik.containo.us/v1alpha1\nkind: Middleware\nmetadata:\n  name: auth-middleware\nspec:\n  forwardAuth:\n    address: http://oauth2-proxy:4180/oauth2/auth\n    trustForwardHeader: true\n    authResponseHeaders:\n      - X-Auth-Request-User\n      - X-Auth-Request-Email\n      - X-Auth-Request-Groups",
        "metadata": { "language": "yaml" }
      },
      {
        "type": "heading",
        "content": "Role-Based Access Control",
        "metadata": { "level": 3 }
      },
      {
        "type": "text",
        "content": "Set up Keycloak realms and clients with appropriate roles. Implement RBAC by checking group membership in your application. OAuth2-Proxy passes user groups via headers for fine-grained authorization."
      },
      {
        "type": "callout",
        "content": "Always validate authorization in your application layer, even with OAuth2-Proxy. Defense in depth is essential for security.",
        "metadata": { "calloutType": "warning" }
      },
      {
        "type": "heading",
        "content": "Security Best Practices",
        "metadata": { "level": 2 }
      },
      {
        "type": "text",
        "content": "Security must be built into every layer of your authentication system:"
      },
      {
        "type": "code",
        "content": "# Security headers configuration\nheaders:\n  customResponseHeaders:\n    Strict-Transport-Security: \"max-age=63072000\"\n    X-Frame-Options: \"DENY\"\n    X-Content-Type-Options: \"nosniff\"\n    Referrer-Policy: \"strict-origin-when-cross-origin\"\n    Permissions-Policy: \"geolocation=(), microphone=(), camera=()\"\n  contentSecurityPolicy: \"default-src 'self'; script-src 'self'; style-src 'self' 'unsafe-inline'\"",
        "metadata": { "language": "yaml" }
      },
      {
        "type": "text",
        "content": "Always use HTTPS in production. Implement CSRF protection for state-changing operations. Set proper CORS headers to prevent unauthorized cross-origin requests. Use short-lived access tokens (15 minutes) with refresh tokens for extended sessions. Monitor authentication failures and implement rate limiting to prevent brute force attacks."
      },
      {
        "type": "callout",
        "content": "Store session data in Redis with appropriate TTLs. Never store sensitive data in browser storage. Use httpOnly, secure, and sameSite cookies.",
        "metadata": { "calloutType": "important" }
      },
      {
        "type": "heading",
        "content": "Real-World Results",
        "metadata": { "level": 2 }
      },
      {
        "type": "text",
        "content": "Our authentication gateway protects 11 microservices and serves 5,181+ active users. The zero-trust architecture ensures every request is validated while providing seamless SSO experience. Users authenticate once and access all applications without repeated logins."
      },
      {
        "type": "callout",
        "content": "With proper monitoring, we detected and blocked 200+ unauthorized access attempts in the first month. Security monitoring is not optional.",
        "metadata": { "calloutType": "tip" }
      },
      {
        "type": "text",
        "content": "The result: a secure, scalable authentication system that protects sensitive university data while providing seamless user experience across multiple applications. Response times remain under 100ms for authenticated requests, and the system scales horizontally to handle traffic spikes."
      }
    ]
  },
  {
    "id": "docker-observability",
    "title": "COMPREHENSIVE OBSERVABILITY FOR DOCKER MICROSERVICES",
    "date": "2024-09-22",
    "excerpt": "Building a complete monitoring stack with Prometheus, Grafana, Loki, and OpenTelemetry for 11-service Docker architecture.",
    "tags": ["docker", "prometheus", "grafana", "observability"],
    "readTime": "10 min",
    "featured": true,
    "relatedProjectIds": ["observability-infrastructure"],
    "contentBlocks": [
      {
        "type": "text",
        "content": "You can't fix what you can't see. Observability is essential for running production microservices. Here's how we built comprehensive monitoring infrastructure that provides visibility into every layer of our stack serving 5,000+ users."
      },
      {
        "type": "callout",
        "content": "Observability is not optional. Without it, you're flying blind in production. Instrument from day one, not after the first incident.",
        "metadata": { "calloutType": "warning" }
      },
      {
        "type": "heading",
        "content": "The Three Pillars of Observability",
        "metadata": { "level": 2 }
      },
      {
        "type": "text",
        "content": "Complete observability requires three complementary approaches: metrics with Prometheus, logs with Grafana Loki, and traces with OpenTelemetry. Each provides different insights, and together they give you complete visibility into system behavior."
      },
      {
        "type": "diagram",
        "content": "graph TB\n    subgraph Applications\n        A[FastAPI Service 1]\n        B[FastAPI Service 2]\n        C[FastAPI Service N]\n    end\n    subgraph Metrics\n        D[Prometheus]\n        E[Grafana]\n    end\n    subgraph Logs\n        F[Promtail]\n        G[Loki]\n    end\n    subgraph Traces\n        H[OpenTelemetry Collector]\n        I[Tempo]\n    end\n    A --> D\n    B --> D\n    C --> D\n    A --> F\n    B --> F\n    C --> F\n    A --> H\n    B --> H\n    C --> H\n    D --> E\n    F --> G\n    G --> E\n    H --> I\n    I --> E",
        "metadata": { "diagramType": "mermaid" }
      },
      {
        "type": "heading",
        "content": "Metrics with Prometheus",
        "metadata": { "level": 2 }
      },
      {
        "type": "text",
        "content": "Prometheus collects time-series metrics from all services. Instrument your FastAPI applications with prometheus-client to expose custom metrics that matter to your business and operations."
      },
      {
        "type": "code",
        "content": "from prometheus_client import Counter, Histogram, generate_latest\nfrom fastapi import FastAPI, Response\nimport time\n\napp = FastAPI()\n\n# Define metrics\nrequest_count = Counter(\n    'http_requests_total',\n    'Total HTTP requests',\n    ['method', 'endpoint', 'status']\n)\n\nrequest_duration = Histogram(\n    'http_request_duration_seconds',\n    'HTTP request latency',\n    ['method', 'endpoint']\n)\n\n@app.middleware('http')\nasync def prometheus_middleware(request, call_next):\n    start = time.time()\n    response = await call_next(request)\n    duration = time.time() - start\n    \n    request_count.labels(\n        method=request.method,\n        endpoint=request.url.path,\n        status=response.status_code\n    ).inc()\n    \n    request_duration.labels(\n        method=request.method,\n        endpoint=request.url.path\n    ).observe(duration)\n    \n    return response\n\n@app.get('/metrics')\ndef metrics():\n    return Response(content=generate_latest(), media_type='text/plain')",
        "metadata": { "language": "python" }
      },
      {
        "type": "text",
        "content": "Track what matters: request rates, error rates, latency percentiles (p50, p95, p99), business metrics like scans processed, and resource utilization (CPU, memory, connections). Create dashboards in Grafana to visualize trends and set alerts for anomalies."
      },
      {
        "type": "heading",
        "content": "Logs with Grafana Loki",
        "metadata": { "level": 2 }
      },
      {
        "type": "text",
        "content": "Grafana Loki aggregates logs from all containers using Promtail. Use structured logging with Structlog to make logs searchable and correlatable. Include request IDs to trace requests across services."
      },
      {
        "type": "code",
        "content": "import structlog\nimport uuid\nfrom fastapi import Request\n\nstructlog.configure(\n    processors=[\n        structlog.processors.TimeStamper(fmt='iso'),\n        structlog.stdlib.add_log_level,\n        structlog.processors.JSONRenderer()\n    ],\n    wrapper_class=structlog.stdlib.BoundLogger,\n    logger_factory=structlog.stdlib.LoggerFactory(),\n)\n\nlogger = structlog.get_logger()\n\n@app.middleware('http')\nasync def logging_middleware(request: Request, call_next):\n    request_id = str(uuid.uuid4())\n    request.state.request_id = request_id\n    \n    logger.info(\n        'request_started',\n        request_id=request_id,\n        method=request.method,\n        path=request.url.path,\n        client=request.client.host\n    )\n    \n    response = await call_next(request)\n    \n    logger.info(\n        'request_completed',\n        request_id=request_id,\n        status_code=response.status_code\n    )\n    \n    return response",
        "metadata": { "language": "python" }
      },
      {
        "type": "callout",
        "content": "Structured logging is a game-changer. JSON logs are searchable, parseable, and correlatable. Never go back to parsing text logs.",
        "metadata": { "calloutType": "tip" }
      },
      {
        "type": "heading",
        "content": "Traces with OpenTelemetry",
        "metadata": { "level": 2 }
      },
      {
        "type": "text",
        "content": "OpenTelemetry provides distributed tracing. See exactly how requests flow through your microservices, identify bottlenecks, and understand dependencies. The automatic instrumentation for FastAPI makes adoption straightforward."
      },
      {
        "type": "code",
        "content": "from opentelemetry import trace\nfrom opentelemetry.instrumentation.fastapi import FastAPIInstrumentor\nfrom opentelemetry.sdk.trace import TracerProvider\nfrom opentelemetry.sdk.trace.export import BatchSpanProcessor\nfrom opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter\n\n# Configure tracing\ntrace.set_tracer_provider(TracerProvider())\ntracer = trace.get_tracer(__name__)\n\n# Export to OpenTelemetry Collector\notlp_exporter = OTLPSpanExporter(\n    endpoint='http://otel-collector:4317',\n    insecure=True\n)\ntrace.get_tracer_provider().add_span_processor(\n    BatchSpanProcessor(otlp_exporter)\n)\n\n# Instrument FastAPI automatically\nFastAPIInstrumentor.instrument_app(app)\n\n# Custom spans for business logic\n@app.post('/process')\nasync def process_data(data: dict):\n    with tracer.start_as_current_span('validate_data'):\n        # Validation logic\n        pass\n    \n    with tracer.start_as_current_span('save_to_database'):\n        # Database operations\n        pass\n    \n    return {'status': 'processed'}",
        "metadata": { "language": "python" }
      },
      {
        "type": "heading",
        "content": "Docker Compose Setup",
        "metadata": { "level": 2 }
      },
      {
        "type": "text",
        "content": "Deploy the complete monitoring stack with Docker Compose. This setup runs alongside your microservices and collects data automatically."
      },
      {
        "type": "code",
        "content": "version: '3.8'\n\nservices:\n  prometheus:\n    image: prom/prometheus:latest\n    volumes:\n      - ./prometheus.yml:/etc/prometheus/prometheus.yml\n      - prometheus-data:/prometheus\n    ports:\n      - '9090:9090'\n    command:\n      - '--config.file=/etc/prometheus/prometheus.yml'\n      - '--storage.tsdb.retention.time=30d'\n\n  grafana:\n    image: grafana/grafana:latest\n    volumes:\n      - grafana-data:/var/lib/grafana\n      - ./grafana/dashboards:/etc/grafana/provisioning/dashboards\n    ports:\n      - '3000:3000'\n    environment:\n      - GF_SECURITY_ADMIN_PASSWORD=admin\n\n  loki:\n    image: grafana/loki:latest\n    ports:\n      - '3100:3100'\n    volumes:\n      - loki-data:/loki\n\n  promtail:\n    image: grafana/promtail:latest\n    volumes:\n      - /var/lib/docker/containers:/var/lib/docker/containers:ro\n      - ./promtail.yml:/etc/promtail/config.yml\n    command: -config.file=/etc/promtail/config.yml\n\nvolumes:\n  prometheus-data:\n  grafana-data:\n  loki-data:",
        "metadata": { "language": "yaml" }
      },
      {
        "type": "heading",
        "content": "Creating Effective Dashboards",
        "metadata": { "level": 2 }
      },
      {
        "type": "text",
        "content": "Build Grafana dashboards that tell a story. Start with high-level metrics (request rate, error rate, latency) then drill down into service-specific details. Use variables to filter by service, environment, or time range."
      },
      {
        "type": "callout",
        "content": "The RED method: Rate, Errors, Duration. These three metrics give you 80% of what you need to know about service health.",
        "metadata": { "calloutType": "important" }
      },
      {
        "type": "heading",
        "content": "Alerting Rules",
        "metadata": { "level": 2 }
      },
      {
        "type": "text",
        "content": "Set up Prometheus alerting rules for critical conditions. Alert on symptoms (user-facing issues) not causes. Group related alerts to avoid alert fatigue."
      },
      {
        "type": "code",
        "content": "groups:\n  - name: api_alerts\n    rules:\n      - alert: HighErrorRate\n        expr: |\n          rate(http_requests_total{status=~\"5..\"}[5m])\n          / rate(http_requests_total[5m]) > 0.05\n        for: 5m\n        labels:\n          severity: critical\n        annotations:\n          summary: \"High error rate detected\"\n          description: \"Error rate is {{ $value | humanizePercentage }}\"\n\n      - alert: HighLatency\n        expr: |\n          histogram_quantile(0.95,\n            rate(http_request_duration_seconds_bucket[5m])\n          ) > 1\n        for: 10m\n        labels:\n          severity: warning\n        annotations:\n          summary: \"High request latency\"\n          description: \"P95 latency is {{ $value }}s\"",
        "metadata": { "language": "yaml" }
      },
      {
        "type": "heading",
        "content": "Real-World Results",
        "metadata": { "level": 2 }
      },
      {
        "type": "text",
        "content": "Our 11-service architecture processes 500+ daily interactions across 11+ database tables. With proper observability, we maintain 99.9% uptime and can debug issues in minutes instead of hours. When problems occur, we have the data to understand exactly what happened and why."
      },
      {
        "type": "callout",
        "content": "Observability paid for itself the first time we used it to debug a production issue. What would have taken hours was resolved in 10 minutes.",
        "metadata": { "calloutType": "tip" }
      },
      {
        "type": "text",
        "content": "The key is making observability a first-class concern from the start. Instrument your code, deploy the monitoring stack, create dashboards, and set up alerts. Your future self will thank you when the 3 AM page comes in and you can quickly identify and resolve the issue."
      }
    ]
  },
  {
    "id": "postgresql-performance",
    "title": "POSTGRESQL PERFORMANCE OPTIMIZATION FOR HIGH-TRAFFIC APPLICATIONS",
    "date": "2024-08-30",
    "excerpt": "Techniques for optimizing PostgreSQL databases handling real-time analytics and high concurrent user loads.",
    "tags": ["postgresql", "database", "performance", "backend"],
    "readTime": "12 min",
    "featured": false,
    "contentBlocks": [
      {
        "type": "text",
        "content": "PostgreSQL is incredibly powerful, but it requires proper tuning for high-traffic applications. Here are the techniques we used to maintain sub-second response times while serving 5,000+ users with real-time analytics."
      },
      {
        "type": "heading",
        "content": "Indexing Strategy",
        "metadata": { "level": 2 }
      },
      {
        "type": "text",
        "content": "Indexes are the foundation of database performance. Analyze your query patterns and create appropriate indexes, but understand the tradeoffs. Every index speeds up reads but slows down writes."
      },
      {
        "type": "code",
        "content": "-- Analyze query performance\nEXPLAIN ANALYZE\nSELECT * FROM scans\nWHERE user_id = 123\nAND created_at > NOW() - INTERVAL '30 days';\n\n-- B-tree index for equality and range queries\nCREATE INDEX idx_scans_user_created\nON scans(user_id, created_at DESC);\n\n-- Partial index for filtered queries\nCREATE INDEX idx_active_users\nON users(email)\nWHERE is_active = true;\n\n-- Covering index to avoid table lookups\nCREATE INDEX idx_scans_summary\nON scans(user_id)\nINCLUDE (scan_type, created_at);",
        "metadata": { "language": "sql" }
      },
      {
        "type": "callout",
        "content": "Use EXPLAIN ANALYZE, not just EXPLAIN. The actual execution plan can differ significantly from the estimated plan.",
        "metadata": { "calloutType": "tip" }
      },
      {
        "type": "text",
        "content": "Don't over-index. Each index requires storage and maintenance overhead. Focus on indexes that support your most common and critical queries. Use pg_stat_user_indexes to identify unused indexes and remove them."
      },
      {
        "type": "heading",
        "content": "Connection Pooling",
        "metadata": { "level": 2 }
      },
      {
        "type": "text",
        "content": "Database connections are expensive. Use a connection pool like PgBouncer to manage connections efficiently and prevent connection exhaustion under high load."
      },
      {
        "type": "code",
        "content": "# PgBouncer configuration\n[databases]\nmydb = host=localhost port=5432 dbname=production\n\n[pgbouncer]\npool_mode = transaction\nmax_client_conn = 1000\ndefault_pool_size = 25\nreserve_pool_size = 5\nreserve_pool_timeout = 3\n\n# SQLAlchemy async configuration\nfrom sqlalchemy.ext.asyncio import create_async_engine\n\nengine = create_async_engine(\n    'postgresql+asyncpg://user:pass@pgbouncer:6432/mydb',\n    pool_size=20,\n    max_overflow=10,\n    pool_pre_ping=True,\n    echo_pool=True\n)",
        "metadata": { "language": "python" }
      },
      {
        "type": "text",
        "content": "Configure pool sizes based on your workload. Monitor connection usage with pg_stat_activity to avoid exhaustion. Use transaction pooling mode for maximum efficiency with stateless applications."
      },
      {
        "type": "heading",
        "content": "Query Optimization",
        "metadata": { "level": 2 }
      },
      {
        "type": "text",
        "content": "Efficient queries are critical for performance. Avoid common pitfalls like N+1 queries and unindexed lookups."
      },
      {
        "type": "heading",
        "content": "Avoiding N+1 Queries",
        "metadata": { "level": 3 }
      },
      {
        "type": "code",
        "content": "# Bad: N+1 query problem\nusers = await session.execute(select(User))\nfor user in users.scalars():\n    # This executes a separate query for each user!\n    scans = await session.execute(\n        select(Scan).where(Scan.user_id == user.id)\n    )\n\n# Good: Use joins or eager loading\nresult = await session.execute(\n    select(User)\n    .options(selectinload(User.scans))\n)\nusers = result.scalars().all()\n\n# Alternative: Use a join\nresult = await session.execute(\n    select(User, Scan)\n    .join(Scan, User.id == Scan.user_id)\n)\n\n# For simple cases, use window functions\nSELECT \n    u.*,\n    COUNT(s.id) OVER (PARTITION BY u.id) as scan_count\nFROM users u\nLEFT JOIN scans s ON u.id = s.user_id;",
        "metadata": { "language": "python" }
      },
      {
        "type": "heading",
        "content": "Pagination and Result Limits",
        "metadata": { "level": 3 }
      },
      {
        "type": "code",
        "content": "-- Keyset pagination (faster for large offsets)\nSELECT * FROM scans\nWHERE (created_at, id) < ($1, $2)\nORDER BY created_at DESC, id DESC\nLIMIT 50;\n\n-- Materialized view for expensive aggregations\nCREATE MATERIALIZED VIEW daily_stats AS\nSELECT \n    DATE(created_at) as date,\n    COUNT(*) as scan_count,\n    COUNT(DISTINCT user_id) as unique_users\nFROM scans\nGROUP BY DATE(created_at);\n\nCREATE INDEX idx_daily_stats_date ON daily_stats(date);\n\n-- Refresh materialized view periodically\nREFRESH MATERIALIZED VIEW CONCURRENTLY daily_stats;",
        "metadata": { "language": "sql" }
      },
      {
        "type": "callout",
        "content": "Materialized views are perfect for dashboards and reports. They cache expensive aggregations and can be refreshed on a schedule.",
        "metadata": { "calloutType": "important" }
      },
      {
        "type": "heading",
        "content": "Database Design",
        "metadata": { "level": 2 }
      },
      {
        "type": "text",
        "content": "Good schema design prevents performance problems before they start. Normalize for data integrity, but denormalize strategically for performance."
      },
      {
        "type": "code",
        "content": "-- Use appropriate data types\nCREATE TABLE scans (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    user_id UUID NOT NULL REFERENCES users(id),\n    scan_type VARCHAR(50) NOT NULL,\n    metadata JSONB,  -- Use JSONB for semi-structured data\n    created_at TIMESTAMPTZ DEFAULT NOW(),\n    \n    -- Add constraints for data integrity\n    CONSTRAINT valid_scan_type \n        CHECK (scan_type IN ('qr', 'barcode', 'nfc')),\n    CONSTRAINT metadata_not_empty \n        CHECK (jsonb_typeof(metadata) = 'object')\n);\n\n-- Index for JSONB queries\nCREATE INDEX idx_scans_metadata \nON scans USING GIN (metadata);\n\n-- Partition large tables by date\nCREATE TABLE scans_partitioned (\n    LIKE scans INCLUDING ALL\n) PARTITION BY RANGE (created_at);\n\nCREATE TABLE scans_2024_11 \nPARTITION OF scans_partitioned\nFOR VALUES FROM ('2024-11-01') TO ('2024-12-01');\n\nCREATE TABLE scans_2024_12 \nPARTITION OF scans_partitioned\nFOR VALUES FROM ('2024-12-01') TO ('2025-01-01');",
        "metadata": { "language": "sql" }
      },
      {
        "type": "text",
        "content": "Partitioning is essential for tables with time-series data. Query performance improves dramatically when PostgreSQL can eliminate entire partitions from the scan."
      },
      {
        "type": "heading",
        "content": "Monitoring and Maintenance",
        "metadata": { "level": 2 }
      },
      {
        "type": "text",
        "content": "Continuous monitoring prevents performance degradation. Track query performance, connection usage, and table statistics."
      },
      {
        "type": "code",
        "content": "-- Find slow queries\nSELECT \n    query,\n    calls,\n    total_exec_time,\n    mean_exec_time,\n    max_exec_time\nFROM pg_stat_statements\nORDER BY mean_exec_time DESC\nLIMIT 10;\n\n-- Check index usage\nSELECT \n    schemaname,\n    tablename,\n    indexname,\n    idx_scan,\n    idx_tup_read,\n    idx_tup_fetch\nFROM pg_stat_user_indexes\nWHERE idx_scan = 0\nORDER BY pg_size_pretty(pg_relation_size(indexrelid)) DESC;\n\n-- Monitor connection counts\nSELECT \n    state,\n    COUNT(*)\nFROM pg_stat_activity\nGROUP BY state;\n\n-- Check table bloat (needs VACUUM)\nSELECT \n    schemaname,\n    tablename,\n    n_dead_tup,\n    n_live_tup,\n    ROUND(n_dead_tup * 100.0 / NULLIF(n_live_tup + n_dead_tup, 0), 2) as dead_pct\nFROM pg_stat_user_tables\nWHERE n_dead_tup > 1000\nORDER BY dead_pct DESC;",
        "metadata": { "language": "sql" }
      },
      {
        "type": "callout",
        "content": "Enable pg_stat_statements extension for query performance tracking. It's essential for identifying bottlenecks in production.",
        "metadata": { "calloutType": "warning" }
      },
      {
        "type": "text",
        "content": "Run VACUUM ANALYZE regularly to maintain table statistics and reclaim space. Consider autovacuum tuning for high-write workloads. Set up monitoring alerts for connection exhaustion, slow queries, and replication lag."
      },
      {
        "type": "heading",
        "content": "Real-World Results",
        "metadata": { "level": 2 }
      },
      {
        "type": "text",
        "content": "Our analytics pipeline processes 11+ table schemas with real-time event sourcing while maintaining 99.9% uptime. Query response times average under 100ms for indexed lookups and under 2 seconds for complex aggregations."
      },
      {
        "type": "diagram",
        "content": "graph LR\n    A[Application] --> B[PgBouncer]\n    B --> C[Primary DB]\n    C --> D[Read Replica 1]\n    C --> E[Read Replica 2]\n    A --> D\n    A --> E\n    F[Analytics] --> E\n    G[Prometheus] --> C\n    G --> D\n    G --> E",
        "metadata": { "diagramType": "mermaid" }
      },
      {
        "type": "text",
        "content": "Proper optimization enabled us to handle 5,000+ concurrent users with minimal hardware. The key is measuring first, optimizing second. Use the built-in PostgreSQL monitoring tools to identify bottlenecks, then apply targeted optimizations."
      },
      {
        "type": "callout",
        "content": "Premature optimization is the root of all evil, but measuring is not premature. Always instrument and monitor from day one.",
        "metadata": { "calloutType": "tip" }
      }
    ]
  },
  {
    "id": "ci-cd-best-practices",
    "title": "CI/CD BEST PRACTICES WITH GITHUB ACTIONS",
    "date": "2024-07-18",
    "excerpt": "Building reliable deployment pipelines with automated testing, container builds, and zero-downtime deployments.",
    "tags": ["cicd", "github-actions", "devops", "automation"],
    "readTime": "9 min",
    "featured": true,
    "relatedProjectIds": ["cicd-pipeline"],
    "contentBlocks": [
      {
        "type": "text",
        "content": "Continuous Integration and Continuous Deployment enable shipping features faster while maintaining quality. Here's how we built CI/CD pipelines that reduced deployment time from hours to minutes while serving 5,000+ users."
      },
      {
        "type": "heading",
        "content": "Why GitHub Actions?",
        "metadata": { "level": 2 }
      },
      {
        "type": "text",
        "content": "GitHub Actions provides powerful workflow automation directly integrated with your repository. Native integration means no external configuration, and the marketplace offers thousands of pre-built actions."
      },
      {
        "type": "diagram",
        "content": "graph LR\n    A[Push Code] --> B[GitHub Actions]\n    B --> C[Run Tests]\n    B --> D[Type Checking]\n    B --> E[Security Scan]\n    C --> F{All Pass?}\n    D --> F\n    E --> F\n    F -->|Yes| G[Build Container]\n    G --> H[Push to Registry]\n    H --> I[Deploy]\n    I --> J[Health Check]\n    J -->|Fail| K[Rollback]\n    J -->|Pass| L[Complete]\n    F -->|No| M[Fail Build]",
        "metadata": { "diagramType": "mermaid" }
      },
      {
        "type": "heading",
        "content": "Automated Testing Pipeline",
        "metadata": { "level": 2 }
      },
      {
        "type": "text",
        "content": "Quality gates are essential. Your CI pipeline should catch issues before they reach production."
      },
      {
        "type": "code",
        "content": "name: Test\n\non:\n  push:\n    branches: [main, develop]\n  pull_request:\n    branches: [main]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        python-version: ['3.10', '3.11', '3.12']\n    \n    steps:\n      - uses: actions/checkout@v4\n      \n      - name: Set up Python\n        uses: actions/setup-python@v5\n        with:\n          python-version: ${{ matrix.python-version }}\n          cache: 'pip'\n      \n      - name: Install dependencies\n        run: |\n          pip install -r requirements.txt\n          pip install pytest pytest-cov mypy black ruff pip-audit\n      \n      - name: Run type checking\n        run: mypy src/\n      \n      - name: Check formatting\n        run: |\n          black --check src/\n          ruff check src/\n      \n      - name: Run security audit\n        run: pip-audit\n      \n      - name: Run tests with coverage\n        run: |\n          pytest tests/ \\\n            --cov=src \\\n            --cov-report=xml \\\n            --cov-report=term \\\n            --cov-fail-under=80\n      \n      - name: Upload coverage\n        uses: codecov/codecov-action@v3\n        with:\n          file: ./coverage.xml",
        "metadata": { "language": "yaml" }
      },
      {
        "type": "callout",
        "content": "Use matrix builds to test across multiple Python versions. Catch compatibility issues before your users do.",
        "metadata": { "calloutType": "tip" }
      },
      {
        "type": "heading",
        "content": "Optimized Container Builds",
        "metadata": { "level": 2 }
      },
      {
        "type": "text",
        "content": "Multi-stage Docker builds minimize image size and improve security. Layer caching makes rebuilds fast."
      },
      {
        "type": "code",
        "content": "# Multi-stage Dockerfile\nFROM python:3.11-slim as builder\n\nWORKDIR /app\n\n# Install dependencies in a separate layer\nCOPY requirements.txt .\nRUN pip install --user --no-cache-dir -r requirements.txt\n\n# Production stage\nFROM python:3.11-slim\n\nWORKDIR /app\n\n# Copy only what's needed\nCOPY --from=builder /root/.local /root/.local\nCOPY src/ ./src/\n\n# Add user for security\nRUN useradd -m -u 1000 appuser && chown -R appuser:appuser /app\nUSER appuser\n\nENV PATH=/root/.local/bin:$PATH\n\nCMD [\"python\", \"-m\", \"uvicorn\", \"src.main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]",
        "metadata": { "language": "dockerfile" }
      },
      {
        "type": "code",
        "content": "name: Build and Push\n\non:\n  push:\n    branches: [main]\n    tags: ['v*']\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    permissions:\n      contents: read\n      packages: write\n    \n    steps:\n      - uses: actions/checkout@v4\n      \n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v3\n      \n      - name: Log in to Registry\n        uses: docker/login-action@v3\n        with:\n          registry: ghcr.io\n          username: ${{ github.actor }}\n          password: ${{ secrets.GITHUB_TOKEN }}\n      \n      - name: Extract metadata\n        id: meta\n        uses: docker/metadata-action@v5\n        with:\n          images: ghcr.io/${{ github.repository }}\n          tags: |\n            type=ref,event=branch\n            type=semver,pattern={{version}}\n            type=sha,prefix={{branch}}-\n      \n      - name: Build and push\n        uses: docker/build-push-action@v5\n        with:\n          context: .\n          push: true\n          tags: ${{ steps.meta.outputs.tags }}\n          labels: ${{ steps.meta.outputs.labels }}\n          cache-from: type=gha\n          cache-to: type=gha,mode=max\n      \n      - name: Scan image\n        uses: aquasecurity/trivy-action@master\n        with:\n          image-ref: ${{ steps.meta.outputs.tags }}\n          format: 'sarif'\n          output: 'trivy-results.sarif'\n      \n      - name: Upload scan results\n        uses: github/codeql-action/upload-sarif@v2\n        with:\n          sarif_file: 'trivy-results.sarif'",
        "metadata": { "language": "yaml" }
      },
      {
        "type": "callout",
        "content": "Never use 'latest' tag in production. Always use specific versions or commit SHAs for reproducibility.",
        "metadata": { "calloutType": "warning" }
      },
      {
        "type": "heading",
        "content": "Zero-Downtime Deployment",
        "metadata": { "level": 2 }
      },
      {
        "type": "text",
        "content": "Rolling deployments ensure users never experience downtime. Health checks validate each instance before routing traffic."
      },
      {
        "type": "code",
        "content": "name: Deploy\n\non:\n  workflow_run:\n    workflows: [\"Build and Push\"]\n    types: [completed]\n    branches: [main]\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n    if: ${{ github.event.workflow_run.conclusion == 'success' }}\n    \n    steps:\n      - uses: actions/checkout@v4\n      \n      - name: Run database migrations\n        run: |\n          docker run --rm \\\n            --network=production \\\n            -e DATABASE_URL=${{ secrets.DATABASE_URL }} \\\n            ghcr.io/${{ github.repository }}:${{ github.sha }} \\\n            alembic upgrade head\n      \n      - name: Deploy with rolling update\n        run: |\n          docker service update \\\n            --image ghcr.io/${{ github.repository }}:${{ github.sha }} \\\n            --update-parallelism 1 \\\n            --update-delay 30s \\\n            --update-order start-first \\\n            --health-cmd \"curl -f http://localhost:8000/health || exit 1\" \\\n            --health-interval 10s \\\n            --health-retries 3 \\\n            production_api\n      \n      - name: Wait for rollout\n        run: |\n          timeout 300 bash -c 'until [ \"$(docker service ps production_api --filter desired-state=running -q | wc -l)\" -eq \"3\" ]; do sleep 5; done'\n      \n      - name: Verify deployment\n        run: |\n          response=$(curl -f -s -o /dev/null -w \"%{http_code}\" https://api.example.com/health)\n          if [ $response -ne 200 ]; then\n            echo \"Health check failed with status $response\"\n            docker service rollback production_api\n            exit 1\n          fi\n      \n      - name: Notify on failure\n        if: failure()\n        uses: slackapi/slack-github-action@v1\n        with:\n          webhook-url: ${{ secrets.SLACK_WEBHOOK }}\n          payload: |\n            {\n              \"text\": \"Deployment failed for ${{ github.repository }}\",\n              \"blocks\": [\n                {\n                  \"type\": \"section\",\n                  \"text\": {\n                    \"type\": \"mrkdwn\",\n                    \"text\": \"*Deployment Failed* :x:\\nRepository: ${{ github.repository }}\\nCommit: ${{ github.sha }}\"\n                  }\n                }\n              ]\n            }",
        "metadata": { "language": "yaml" }
      },
      {
        "type": "heading",
        "content": "Database Migrations",
        "metadata": { "level": 2 }
      },
      {
        "type": "text",
        "content": "Always run migrations before deploying new code. Use Alembic for safe, versioned database changes."
      },
      {
        "type": "code",
        "content": "# Alembic migration example\nfrom alembic import op\nimport sqlalchemy as sa\n\ndef upgrade():\n    # Add column with default for existing rows\n    op.add_column(\n        'scans',\n        sa.Column('status', sa.String(50), nullable=True)\n    )\n    \n    # Backfill existing rows\n    op.execute(\n        \"UPDATE scans SET status = 'completed' WHERE status IS NULL\"\n    )\n    \n    # Make column NOT NULL after backfill\n    op.alter_column('scans', 'status', nullable=False)\n    \n    # Add index for new column\n    op.create_index(\n        'idx_scans_status',\n        'scans',\n        ['status']\n    )\n\ndef downgrade():\n    op.drop_index('idx_scans_status', table_name='scans')\n    op.drop_column('scans', 'status')",
        "metadata": { "language": "python" }
      },
      {
        "type": "callout",
        "content": "Always write reversible migrations. You should be able to roll back any change without data loss.",
        "metadata": { "calloutType": "important" }
      },
      {
        "type": "heading",
        "content": "Monitoring and Observability",
        "metadata": { "level": 2 }
      },
      {
        "type": "text",
        "content": "Track deployment metrics to understand pipeline health and identify bottlenecks."
      },
      {
        "type": "code",
        "content": "name: Deployment Metrics\n\non:\n  workflow_run:\n    workflows: [\"Deploy\"]\n    types: [completed]\n\njobs:\n  metrics:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Record deployment metrics\n        run: |\n          curl -X POST https://api.example.com/metrics \\\n            -H \"Content-Type: application/json\" \\\n            -d '{\n              \"metric\": \"deployment.completed\",\n              \"value\": 1,\n              \"tags\": {\n                \"status\": \"${{ github.event.workflow_run.conclusion }}\",\n                \"branch\": \"${{ github.ref_name }}\",\n                \"duration\": \"${{ github.event.workflow_run.duration }}\"\n              }\n            }'\n      \n      - name: Check error rate\n        run: |\n          error_rate=$(curl -s https://api.example.com/metrics/errors | jq '.rate')\n          if (( $(echo \"$error_rate > 0.05\" | bc -l) )); then\n            echo \"Error rate too high: $error_rate\"\n            # Trigger automatic rollback\n            curl -X POST https://api.example.com/rollback \\\n              -H \"Authorization: Bearer ${{ secrets.API_TOKEN }}\"\n            exit 1\n          fi",
        "metadata": { "language": "yaml" }
      },
      {
        "type": "heading",
        "content": "Real-World Results",
        "metadata": { "level": 2 }
      },
      {
        "type": "text",
        "content": "Our CI/CD pipeline enables multiple deployments per day with confidence. Automated testing catches 95% of bugs before code review. Zero-downtime deployments ensure 5,000+ users never experience service interruptions."
      },
      {
        "type": "callout",
        "content": "We reduced deployment time from 2 hours of manual work to 8 minutes of automated deployment. The ROI on CI/CD automation is immediate.",
        "metadata": { "calloutType": "tip" }
      },
      {
        "type": "text",
        "content": "Key principle: automate everything, but make it easy to override when needed. The best pipelines are reliable, fast, and transparent. Developers should trust the pipeline and understand what it does at every step."
      },
      {
        "type": "callout",
        "content": "Start simple and iterate. A basic CI/CD pipeline that works is better than a complex one that's always breaking.",
        "metadata": { "calloutType": "important" }
      }
    ]
  }
]
